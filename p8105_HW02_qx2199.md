Homework 2
================
Qianhui Xu

``` r
library(tidyverse)
```

    ## ── Attaching packages ───────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ──────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

\#Problem 1

\#\#First, define a path to the Trash Wheel dataset.

``` r
path_trashwheel = "./Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```

\#\#Read and clean the Mr. Trash Wheel dataset.

``` r
trashwheel_df = 
    read_excel(
        path = path_trashwheel,
        sheet = "Mr. Trash Wheel",
        range = cell_cols("A2:N408")) %>% 
    janitor::clean_names() %>% 
  drop_na(dumpster) %>%
    mutate(
        sports_balls = round(sports_balls),
        sports_balls = as.integer(sports_balls)
    )
```

    ## New names:
    ## * `` -> ...15
    ## * `` -> ...16
    ## * `` -> ...17

\#\#Read and clean precipitation data for 2018 and 2017.

``` r
precipitation_2017 = 
    read_excel(
      path = path_trashwheel,
        sheet = "2017 Precipitation",
        skip = 1
    ) %>% 
    janitor::clean_names() %>% 
    drop_na(month) %>% 
    mutate(year = 2017) %>% 
    relocate(year)


precipitation_2018 = 
    read_excel(
      path = path_trashwheel,
        sheet = "2018 Precipitation",
        skip = 1
    ) %>% 
    janitor::clean_names() %>% 
    drop_na(month) %>% 
    mutate(year = 2018) %>% 
    relocate(year)
```

\#\#Now combine annual precipitation dataframes. In the following code
chunk, I create a `month_df` dataframe.

``` r
month_df = 
    tibble(
        month = 1:12,
        month_name = month.name
    )
precipitation_bind_df = 
    bind_rows(precipitation_2018, precipitation_2017)

precipitation_bind_df = 
    left_join(precipitation_bind_df, month_df, by = "month")
```

\#\#data description This dataset contains information from the
Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters
the inner harbor, the trashwheel collects that trash, and stores it in a
dumpster. The dataset contains information on year, month, and trash
collected, include some specific kinds of trash.

There are a total of 344 rows in our final dataset.There are a total of
24 rows in the combined precipitation dataset of 2017 and 2018.

The median number of sports balls found in a dumpster in 2017 was 8 The
total precipitation in 2018 was 70.33 inches.

\#Problem 2

\#\#First, define a path to the NYC Transit dataset.

``` r
path_subway = "./NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
```

, \#\#Read and clean NYC subway data. \#\#\#Here we firstly read the
dataset, then we need to make sure that the types of each variablebe the
type that we want. We first notice that the variable entry and variable
vending is stored as character variables, and we need to switch them
into logic variables.Also, we could notice that some of the route
variables (route8,route9,route10,route10,route11) are double, we need to
switch the type of the route variable into character variable.

``` r
nyc_subway_df = 
      read_csv(
             file = path_subway,
             col_types = cols( Route8 = col_character(), Route9 = col_character() , Route10 = col_character() , Route11 = col_character() )
             ) %>% 
      janitor::clean_names() %>% 
      select(line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada) %>% 
   
  mutate(entry = as.logical(ifelse(entry == "YES", 1, 0)
  ))
```

This dataset contains information related to each entrance and exit for
each subway station in NYC. The dataset contains information on 19
variables, such as line, station\_name, station\_latitude,
station\_longitude, route1, route2, route3, route4, route5, route6,
route7, route8, route9, route10, route11, entry, vending,
entrance\_type, ada. There are 1868 rows and 19 columns. There are 465
distinct stations. There are 84 stations that are ADA compliant. The
proportion of station entrances without vending allow entrance is
0.3770492

\#\#Reform the data so that route number and route name are distinct
variables

``` r
nyc_subway_new =
  pivot_longer(
    nyc_subway_df,
    route1:route11,
    names_to = "route_number",
    names_prefix = "route",
    values_to = "route_name",
    )
```

\#\#\#There are 60 distinct stations serve the A train.Among the
stations that serve the A train, 17 stations that are ADA compliant.

\#\#Problem 3

\#\#First, define a path to the “pols\_month” dataset.

\#\#\#Define a path to the pols-month dataset.

``` r
path_pols_month = "./data/pols-month.csv"
```

\#\#\#Read and clean the pols-month dataset, break up the variable mon
into integer variables year, month, and day; replace month number with
month name; create a president variable taking values gop and dem, and
remove prez\_dem and prez\_gop; and remove the day variable.

``` r
pols_month_df = 
  read_csv(path_pols_month) %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-", convert = TRUE) %>% 
  mutate(month = month.name[month]) %>% 
  mutate(president = ifelse(prez_gop == 1, "gop", "dem")) %>% 
  mutate_at(vars(year),as.character) %>% 
  select(-c(prez_gop, prez_dem, day))
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

\#\#\#Second, define a path to the snp dataset.

``` r
path_snp = "./data/snp.csv"
```

\#\#\#Read and clean the snp dataset

``` r
snp_df = 
  read_csv(path_snp) %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), sep = "/", convert = TRUE) %>% 
  mutate(month = month.name[month]) %>% 
   mutate_at(vars(year),as.character)  %>% 
   relocate(year,month) %>% 
select(-day)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

\#\#\#Third, define a path to the unemployment dataset.

``` r
path_unemployment = "./data/unemployment.csv"
```

\#\#\#\#Read and clean the unemployment dataset

``` r
unemployment_df = 
  read_csv(path_unemployment) %>% 
  janitor::clean_names() %>% 
    pivot_longer(
               c( jan:dec ),
                names_to = "month",
                names_prefix = NULL,
                values_to = "unemployment_percentage"
                ) %>% 
                mutate(month = recode(month, "jan" = "January", "feb" =                                                    "February", "mar" = "March",                                                 "apr" = "April", "may" = "May",                                               "jun" = "June", "jul" = "July",                                               "aug" = "August", "sep" =                                                    "September", "oct" = "October",                                                "nov" = "November", "dec" =                                                    "December")) %>% 
                mutate_at(vars(year),as.character)
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

### Join the pols-month,snp and unemployment datasets.

``` r
#merging snp into pols
combine_pols_snp_df =
  left_join(pols_month_df, snp_df, by = c("month", "year"))
#merging
combine_all_df =
  left_join(combine_pols_snp_df, unemployment_df, by = c("month", "year"))
```

\#\#\#Summary

The pols-month dataset contains information on national politicians who
are democratic or republican at any given time.There are 9 variables,
such asyear, month, gov\_gop, sen\_gop, rep\_gop, gov\_dem, sen\_dem,
rep\_dem, president. There are 822 rows and 19 columns.The range of
years is (1947, 2015)

The snp dataset contains information to Standard & Poor’s stock market
index (S\&P), often used as a representative measure of stock market as
a whole. There are 3 variables, such asyear, month, close. There are 787
rows and 3 columns.The range of years is (1950, 2015)

The unemployment dataset contains the information on the percentage of
unemployment on related months and related years.There are 3 variables,
such asyear, month, unemployment\_percentage. There are 816 rows and 3
columns.The range of years is (1948, 2015)

The combine\_all\_df dataset helps to provide the information from three
previous dataset.(pols,snp,unemployment), which give us information on
national politicians,stock market index and percentage of unemployment
on related months and related years.There are 11 variables, such asyear,
month, gov\_gop, sen\_gop, rep\_gop, gov\_dem, sen\_dem, rep\_dem,
president, close, unemployment\_percentage. There are 822 rows and 11
columns.The range of years is (1947, 2015)
